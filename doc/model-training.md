# ðŸ“„ Project Documentation: Predictive Model Training

**To the ML Team:** This document outlines the plan for building a predictive model using the synthetic dataset generated by our simulation pipeline.

### 1. Project Goal

The objective is to build a **time-series classification model**. This model will ingest a sequence of recent sensor data and predict the **probability of a rockfall event** in the immediate future (e.g., the next hour).

### 2. Primary Data Source

* **File:** `master_log.csv`
* **Target Variable (y):** `LABEL` (This must be converted from "STABLE"/"UNSTABLE" to binary `0` / `1`).
* **Feature Columns (X):**
    * `rainfall_mm`
    * `temperature_C`
    * `vibration_hz`
    * `wind_speed_kmh`
    * `ground_saturation_pct`
    * `freeze_thaw_cycles`

*(Note: The `image_file` column is not used in this model. That data is for a separate, future computer vision task. We are focusing on the time-series sensor data, which is the primary driver of prediction.)*

| Expected Data | Where to Find It (in `master_log.csv`) |
| :--- | :--- |
| **Environmental Sensors** | `rainfall_mm`, `temperature_C`, `wind_speed_kmh` |
| **Geotechnical Sensors** | `ground_saturation_pct` (our proxy for pore pressure) <br> `freeze_thaw_cycles` (our proxy for rock strain/weakening) |
| **Trigger Event** | `vibration_hz` (a direct trigger event) |
| **The Result** | `LABEL` (e.g., 'UNSTABLE') and `trigger_reason` |

---

### 3. The ML Problem: Time-Series Classification

This is **not** a standard "look at one row, predict its label" problem.

To predict the label for **Hour H**, the model must analyze the sensor data from **Hours H-24 through H-1**. This 24-hour period is our **"lookback window."** The model will learn patterns *within this sequence* that lead to a failure.

---

### 4. Data Preparation (Feature Engineering)

This is the most critical step. We must convert the flat `master_log.csv` into a 3D "sliding window" dataset.

1.  **Define Lookback:** We'll start with `lookback_window = 24` (hours).
2.  **Normalize Data:** All feature columns must be normalized. Use `StandardScaler` (fit it *only* on the training data, then `transform` both train and test data).
3.  **Create Sequences:** Iterate through the data to build your `X` and `y` arrays.

    * **A single `X` sample will be:** A 2D array (a "sequence") of shape `(24, 6)`.
        * `[24 hours] x [6 features]`
    * **A single `y` sample will be:** The `LABEL` (0 or 1) of the *next* hour (the 25th hour).

    Your final training dataset will have a 3D shape:
    * `X_train` shape: `(num_samples, 24, 6)`
    * `y_train` shape: `(num_samples,)`

---

### 5. Recommended Model Architectures

We will test two main approaches.

#### Option A: The Baseline (XGBoost / LightGBM)

* **How:** These models cannot handle 3D sequence data directly. You must "flatten" the features.
* **Feature Engineering:** Instead of a `(24, 6)` shape, you will create one *very wide* row of `24 * 6 = 144` features.
    * *Example columns:* `rainfall_mm_h-24`, `rainfall_mm_h-23`, ..., `ground_sat_pct_h-2`, `ground_sat_pct_h-1`.
* **Pros:** Very fast to train, good at finding complex patterns, and highly interpretable.
* **Cons:** Loses the "temporal" aspect of the sequence. It just sees 144 independent numbers.

#### Option B: The Advanced Model (LSTM / GRU)

This is the architecturally "correct" model for this problem.

* **How:** Recurrent Neural Networks (RNNs) are *designed* to process sequences.
* **Input Shape:** The model will accept the 3D data directly: `(batch_size, 24, 6)`.
* **Architecture (Example in Keras):**
    ```python
    from tensorflow.keras.models import Sequential
    from tensorflow.keras.layers import Input, LSTM, Dropout, Dense

    model = Sequential([
        Input(shape=(24, 6)), # 24 hours (timesteps), 6 features
        LSTM(units=64, return_sequences=False),
        Dropout(0.3),
        Dense(units=32, activation='relu'),
        Dense(units=1, activation='sigmoid') # This outputs the 0.0-1.0 probability
    ])
    ```
* **Pros:** Understands time and the *order* of events (e.g., "rising saturation for 10 hours *followed by* a vibration" is a pattern it can learn).
* **Cons:** Slower to train, more of a "black box."

---

### 6. Training & Evaluation Strategy

**CRITICAL: Do NOT shuffle your data.**

This is time-series data. You must train on the "past" and test on the "future."

1.  **Train-Test Split:** Find the `global_hour` that splits your data 80/20.
    * `train_data` = All rows from the first 80% of the simulation.
    * `test_data` = All rows from the last 20% of the simulation.
2.  **Metrics:** Your data is imbalanced (many `0`s, few `1`s). **Do not use "Accuracy."**
    * **Primary Metric:** **Recall** for the `UNSTABLE` (1) class. We want to find *all* the real rockfalls. A false positive (alerting when it's safe) is better than a false negative (saying it's safe when it's not).
    * **Secondary Metrics:** **Precision** and **F1-Score** for the `UNSTABLE` class.
    * **Visualization:** A **Confusion Matrix** is mandatory.

---

### 7. Expected Outcome & Backend Integration

The final trained model will be saved as a single file (e.g., `model.pkl` for XGBoost or `model.h5` for the LSTM).

* **Function:** `model.predict(last_24_hours_data)`
* **Output:** A single float value, e.g., `0.85` (85% probability of failure).
* **Backend:** A FastAPI backend will be built. It will have one endpoint: `/predict`.
    * It will receive a JSON payload containing the last 24 hours of sensor data.
    * It will load this data, run `model.predict()`, and return the probability.
    * If the probability is `> 0.8` (our alert threshold), it will also trigger the SMS/email alert function.